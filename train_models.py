#!/usr/bin/env python3
# -*- coding: UTF-8 -*-

"""
DNN_CWS æ¨¡å‹è®­ç»ƒè„šæœ¬
ä½¿ç”¨init.pyç”Ÿæˆçš„è®­ç»ƒæ•°æ®æ¥è®­ç»ƒDNNæ¨¡å‹
"""

import os
import time
from datetime import datetime
import numpy as np
import traceback

import constant
from seg_dnn import SegDNN


def ensure_output_dir():
    """ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨"""
    if not os.path.exists('output'):
        os.makedirs('output')
    if not os.path.exists('model'):
        os.makedirs('model')
    if not os.path.exists('tmp'):
        os.makedirs('tmp')

def check_training_data():
    """æ£€æŸ¥è®­ç»ƒæ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    required_files = [
        'corpus/dict.utf8',
        'corpus/dnn/words_batch_flat.npy',
        'corpus/dnn/labels_batch_flat.npy'
    ]
    
    print("ğŸ” æ£€æŸ¥è®­ç»ƒæ•°æ®æ–‡ä»¶:")
    missing_files = []
    
    for file_path in required_files:
        if os.path.exists(file_path):
            size_mb = os.path.getsize(file_path) / 1024 / 1024
            print(f"âœ… {file_path} ({size_mb:.1f}MB)")
        else:
            print(f"âŒ {file_path}")
            missing_files.append(file_path)
    
    if missing_files:
        print(f"\nâš ï¸  ç¼ºå°‘ {len(missing_files)} ä¸ªè®­ç»ƒæ•°æ®æ–‡ä»¶!")
        print("è¯·å…ˆè¿è¡Œ: python3 init.py")
        return False
    
    print("âœ… æ‰€æœ‰è®­ç»ƒæ•°æ®æ–‡ä»¶å°±ç»ª!")
    return True

def train_dnn_model(epochs=10):
    """è®­ç»ƒä¼˜åŒ–ç‰ˆDNNæ¨¡å‹"""
    print("\nğŸš€ å¼€å§‹è®­ç»ƒDNNæ¨¡å‹...")
    print("=" * 50)
    
    try:
        import tensorflow as tf
        tf.compat.v1.reset_default_graph()

        print("æ­£åœ¨åˆå§‹åŒ–DNNæ¨¡å‹...")
        dnn_model = SegDNN(constant.VOCAB_SIZE, 50, constant.DNN_SKIP_WINDOW)
        
        print(f"æ¨¡å‹å‚æ•°:")
        print(f"  - è¯æ±‡è¡¨å¤§å°: {constant.VOCAB_SIZE}")
        print(f"  - åµŒå…¥ç»´åº¦: 50")
        print(f"  - ç½‘ç»œç»“æ„: 512 -> 256 -> 4")
        print(f"  - æ‰¹å¤§å°: 32")
        print(f"  - è®­ç»ƒè½®æ•°: {epochs}")
        
        start_time = time.time()
        losses, accuracies = dnn_model.train_optimized(epochs=epochs, early_stopping_patience=3)
        training_time = time.time() - start_time
        
        print(f"\nâœ… DNNæ¨¡å‹è®­ç»ƒå®Œæˆ!")
        print(f"æ€»è®­ç»ƒæ—¶é—´: {training_time:.1f}ç§’")
        
        if losses:
            print(f"æœ€ç»ˆæŸå¤±: {losses[-1]:.4f}")
            print(f"æœ€ç»ˆå‡†ç¡®ç‡: {accuracies[-1]:.4f}")
            log_path = f'output/dnn_training_log_{datetime.now().strftime("%Y%m%d_%H%M%S")}.txt'
            with open(log_path, 'w', encoding='utf-8') as f:
                f.write(f"DNNæ¨¡å‹è®­ç»ƒæ—¥å¿—\n"
                        f"è®­ç»ƒæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
                        f"è®­ç»ƒè½®æ•°: {len(losses)}/{epochs}\n"
                        f"æ€»è€—æ—¶: {training_time:.1f}ç§’\n"
                        f"æœ€ç»ˆæŸå¤±: {losses[-1]:.4f}\n"
                        f"æœ€ç»ˆå‡†ç¡®ç‡: {accuracies[-1]:.4f}\n"
                        f"æŸå¤±å†å²: {losses}\n"
                        f"å‡†ç¡®ç‡å†å²: {accuracies}\n")
            print(f"è®­ç»ƒæ—¥å¿—ä¿å­˜åˆ°: {log_path}")
        return True
        
    except Exception as e:
        print(f"âŒ DNNæ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
        traceback.print_exc()
        return False

def test_trained_models():
    """æµ‹è¯•è®­ç»ƒå®Œæˆçš„æ¨¡å‹"""
    print("\nğŸ§ª æµ‹è¯•è®­ç»ƒå®Œæˆçš„æ¨¡å‹...")
    print("=" * 50)
    
    test_sentences = [
        "æˆ‘çˆ±åŒ—äº¬å¤©å®‰é—¨",
        "æ·±åº¦å­¦ä¹ æŠ€æœ¯å‘å±•è¿…é€Ÿ",
        "è‡ªç„¶è¯­è¨€å¤„ç†å¾ˆæœ‰è¶£"
    ]
    
    if not os.path.exists('model/best_model.ckpt.index'):
        print("  ğŸ¤· æ²¡æœ‰æ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹ (model/best_model.ckpt)ï¼Œè·³è¿‡æµ‹è¯•")
        return

    print("æµ‹è¯•DNNæ¨¡å‹ (model/best_model.ckpt):")
    try:
        import tensorflow as tf
        tf.compat.v1.reset_default_graph()
        
        cws = SegDNN(constant.VOCAB_SIZE, 50, constant.DNN_SKIP_WINDOW)
        
        for sentence in test_sentences:
            print("-" * 40)
            result, _ = cws.seg(sentence, debug=True)
            print(f"  Input:  {sentence}")
            print(f"  Output: {' | '.join(result)}")
            print("-" * 40)
            
    except Exception as e:
        print(f"  DNNæµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()

def delete_all_models():
    """ä¸€é”®åˆ é™¤æ‰€æœ‰å†å²æ¨¡å‹"""
    print("\nğŸ—‘ï¸  ä¸€é”®åˆ é™¤æ‰€æœ‰å†å²æ¨¡å‹...")
    print("=" * 50)
    
    model_patterns = ['model/*.ckpt*', 'tmp/*.ckpt*']
    all_files = []
    
    import glob
    for pattern in model_patterns:
        all_files.extend(glob.glob(pattern))
    
    checkpoint_files = ['model/checkpoint', 'tmp/checkpoint']
    for cp_file in checkpoint_files:
        if os.path.exists(cp_file):
            all_files.append(cp_file)
            
    if not all_files:
        print("âœ… æ²¡æœ‰æ‰¾åˆ°å†å²æ¨¡å‹æ–‡ä»¶")
        return
    
    total_size = sum(os.path.getsize(f) for f in all_files)
    print("ğŸ” å‘ç°ä»¥ä¸‹æ¨¡å‹æ–‡ä»¶å°†è¢«åˆ é™¤:")
    for f in all_files:
        print(f"  - {f} ({os.path.getsize(f)/1024/1024:.2f}MB)")
    
    print(f"\nğŸ“Š ç»Ÿè®¡: {len(all_files)} ä¸ªæ–‡ä»¶, æ€»å¤§å°: {total_size/1024/1024:.2f}MB")
    
    try:
        confirm = input(f"\nâš ï¸  ç¡®è®¤åˆ é™¤è¿™ {len(all_files)} ä¸ªæ–‡ä»¶? (y/N): ").strip().lower()
    except EOFError: # Non-interactive mode
        confirm = 'y'

    if confirm in ['y', 'yes']:
        deleted_count = 0
        print("\nğŸ—‘ï¸  æ­£åœ¨åˆ é™¤...")
        for file_path in all_files:
            try:
                os.remove(file_path)
                deleted_count += 1
            except Exception: pass
        print(f"\nğŸ‰ {deleted_count} ä¸ªæ–‡ä»¶åˆ é™¤å®Œæˆ!")
    else:
        print("âŒ å–æ¶ˆåˆ é™¤æ“ä½œ")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ DNN_CWS æ¨¡å‹è®­ç»ƒä¸ç®¡ç†è„šæœ¬")
    print("=" * 60)
    
    ensure_output_dir()
    
    if not check_training_data():
        return
    
    while True:
        try:
            print("\nè¯·é€‰æ‹©æ“ä½œ:")
            print("1. è®­ç»ƒDNNæ¨¡å‹")
            print("2. æµ‹è¯•å·²æœ‰æ¨¡å‹")
            print("3. æ¸…ç†æ‰€æœ‰å†å²æ¨¡å‹")
            print("4. é€€å‡º")
            
            choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-4): ").strip()
            
            if choice == '1':
                epochs_str = input("è¯·è¾“å…¥è®­ç»ƒè½®æ•° (å»ºè®®5-15, é»˜è®¤10): ").strip()
                epochs = int(epochs_str) if epochs_str.isdigit() else 10
                if train_dnn_model(epochs):
                    test_trained_models()
            elif choice == '2':
                test_trained_models()
            elif choice == '3':
                delete_all_models()
            elif choice == '4':
                print("é€€å‡ºè„šæœ¬ã€‚")
                break
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥!")
        except EOFError:
            break
    
    print("\n" + "=" * 60)
    print("âœ… ä»»åŠ¡å®Œæˆ!")

if __name__ == '__main__':
    main()
